{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FiorenSt/Machine-Learning-In-Astronomy-Tutorial/blob/main/DeblendingGalaxiesTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsSOi56nTfrM"
      },
      "source": [
        "#TUTORIAL on Galaxy deblending with Deep Learning\n",
        "\n",
        "###Edited by Fiorenzo Stoppa for Master Student Course\n",
        "\n",
        "###### Credits to Alexandre Boucaud (APC) & Marc Huertas-Company (LERMA) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaaqF1o8TfrP"
      },
      "source": [
        "1. [Introduction](#Introduction)\n",
        "2. [Data](#Data)\n",
        "3. [Workflow](#Workflow)\n",
        "4. [Evaluation](#Detection-evaluation)\n",
        "5. [Local testing/exploration](#Local-testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSJfhlvWTfrP"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In astronomical images, the projection effects may cause two or more galaxies to overlap. When they are barely indistinguishable from one another, they are referred to as _blended_ and this can bias astrophysical estimators such as the morphology of galaxies or the shear (weak gravitational lensing distortion).  \n",
        "As the sensitivity of imaging devices grows, a high fraction of galaxies appear _blended_ in the images, which is a known and important issue for current and upcoming galaxy surveys. It is key to develop methods to enable astronomers to alleviate such effect.\n",
        "We can foresee some features that would help, in which machine learning could provide a solution:\n",
        "- classify an image as containing isolated/blended objects  \n",
        "  ___binary classification___\n",
        "- count the number of blended sources in a blended image  \n",
        "  ___object detection___\n",
        "- find the contours of each object  \n",
        "  ___segmentation___\n",
        "- ...\n",
        "\n",
        "In this tutorial, we will try to identify and localize the 'companion' galaxy. Each images contain **two galaxies** and the goal will be to find the **contours of the companion galaxy**.\n",
        "What is the training set?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBIDYVUvTfrQ"
      },
      "source": [
        "## Code\n",
        "\n",
        "Install the `dltools` lib that contains helper methods for training a deep neural network on the provided blended galaxy dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d--abM09TfrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7fa1be-966a-46be-890b-b1c350aa9070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 462 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for dltools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/aboucaud/deeplearning4astro_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Ob_RkzTfrS"
      },
      "source": [
        "## Necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A40gpCPRTfrS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SE4flr9JTfrT"
      },
      "outputs": [],
      "source": [
        "from dltools.plots import plot_random_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDTssQzJTfrT"
      },
      "source": [
        "## Data\n",
        "\n",
        "Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-fxq9lBETfrU"
      },
      "outputs": [],
      "source": [
        "datadir = \"data\"\n",
        "# Use the big dataset (during the school, use this only on Colab, otherwise set to False)\n",
        "full = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KlfcjZqITfrV"
      },
      "outputs": [],
      "source": [
        "URL = \"https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud\"\n",
        "FOLDER = \"ed127\"\n",
        "FILES = [\n",
        "    \"test_blends_mini.npy\",\n",
        "    \"test_target_masks_mini.npy\",\n",
        "    \"train_blends_mini.npy\",\n",
        "    \"train_target_masks_mini.npy\",\n",
        "\n",
        "]\n",
        "BIG_FILES = [\n",
        "    \"masks.tar.gz\",\n",
        "    \"blends.tar.gz\",\n",
        "]\n",
        "\n",
        "def main(output_dir, delete_archive=False, full=False):\n",
        "    if full:\n",
        "        files = BIG_FILES\n",
        "    else:\n",
        "        files = FILES\n",
        "\n",
        "    urls = [\n",
        "        f\"{URL}/{FOLDER}/{filename}\"\n",
        "        for filename in files\n",
        "    ]\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"Creating directory {output_dir}\")\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    for url, filename in zip(urls, files):\n",
        "        output_file = os.path.join(output_dir, filename)\n",
        "\n",
        "        if os.path.exists(output_file):\n",
        "            print(f\"{filename} already downloaded.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Downloading from {url} ...\")\n",
        "        urlretrieve(url, filename=output_file)\n",
        "        print(f\"=> File saved as {output_file}\")\n",
        "\n",
        "        if filename.endswith(\"tar.gz\"):\n",
        "            print(\"Extracting tarball..\")\n",
        "            with tarfile.open(output_file, \"r:gz\") as f:\n",
        "                f.extractall(output_dir)\n",
        "            print(\"Done.\")\n",
        "\n",
        "            if delete_archive:\n",
        "                os.remove(output_file)\n",
        "                print(f\"=> File {output_file} removed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sav0pjfTfrV",
        "outputId": "de8ea9b0-26c5-4ad4-bb6a-b55c2f331e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directory data\n",
            "Downloading from https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud/ed127/masks.tar.gz ...\n",
            "=> File saved as data/masks.tar.gz\n",
            "Extracting tarball..\n",
            "Done.\n",
            "=> File data/masks.tar.gz removed.\n",
            "Downloading from https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud/ed127/blends.tar.gz ...\n"
          ]
        }
      ],
      "source": [
        "main(output_dir=datadir, full=full, delete_archive=True)                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T12cT9-WTfrW"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxnS-FNTfrW"
      },
      "source": [
        "Load the train and test datasets in memory-mapping mode. This does not actually load the data into memory but creates a mapping to it to easily retrieve chunks of the data using its indices when needed. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiIzFYaDTfrW"
      },
      "outputs": [],
      "source": [
        "suffix = \"\" if full else \"_mini\"\n",
        "\n",
        "X_train = np.load(os.path.join(datadir, f\"train_blends{suffix}.npy\"), mmap_mode='r')\n",
        "Y_train = np.load(os.path.join(datadir, f\"train_target_masks{suffix}.npy\"), mmap_mode='r')[:, 1, :, :]\n",
        "\n",
        "X_test = np.load(os.path.join(datadir, f\"test_blends{suffix}.npy\"), mmap_mode='r')\n",
        "Y_test = np.load(os.path.join(datadir, f\"test_target_masks{suffix}.npy\"), mmap_mode='r')[:, 1, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ocDl6H7TfrX"
      },
      "outputs": [],
      "source": [
        "def plot_data_basic(idx):\n",
        "    titles = [\n",
        "        'blended galaxies',\n",
        "        'segmap of companion galaxy'\n",
        "    ]\n",
        "\n",
        "    fig_size = (12, 6)\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=fig_size)\n",
        "    axes[0].imshow(X_train[idx], cmap='viridis')\n",
        "    axes[1].imshow(Y_train[idx], cmap='Greys_r')\n",
        "    for title, ax in zip(titles, axes):\n",
        "        ax.set_title(title)\n",
        "        ax.set_axis_off()\n",
        "\n",
        "\n",
        "def plot_random_results(X_test, y_test, y_pred):\n",
        "        n_gal = 5\n",
        "        idx = np.random.randint(0, len(y_test), size=n_gal)\n",
        "        X = X_test[idx]\n",
        "        if X.ndim == 3:\n",
        "            X = np.expand_dims(X, -1)\n",
        "        y_true = y_test[idx]\n",
        "        y_pred = y_pred[idx]\n",
        "\n",
        "        titles = [\n",
        "            'blend',\n",
        "            'true segmentation',\n",
        "            'output',\n",
        "            'output thresholded',\n",
        "        ]\n",
        "        fig_size = (10, 12)\n",
        "        fig, ax = plt.subplots(nrows=n_gal, ncols=4, figsize=fig_size)\n",
        "        for i in range(n_gal):\n",
        "            img = np.squeeze(X[i])\n",
        "            yt = np.squeeze(y_true[i])\n",
        "            yp = np.squeeze(y_pred[i])\n",
        "            ax[i, 0].imshow(img)\n",
        "            ax[i, 1].imshow(yt)\n",
        "            ax[i, 2].imshow(yp)\n",
        "            ax[i, 3].imshow(yp.round())\n",
        "            if i == 0:\n",
        "                for idx, a in enumerate(ax[i]):\n",
        "                    a.set_title(titles[idx])\n",
        "            for a in ax[i]:\n",
        "                a.set_axis_off()\n",
        "        #plt.savefig('{filename}'.format(filename=filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KLLATLXTfrX"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(len(X_train))\n",
        "plot_data_basic(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD-7XfpuTfrX"
      },
      "source": [
        "The goal in this exercise is to create a deep learning model that produces the segmentation map (mask) of the companion galaxy from the image of the blend. This can be seen as a classification task where each pixel of the image has to be classified as \"galaxy companion\" or \"not galaxy companion\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ExGQeSfTfrY"
      },
      "source": [
        "## Detection evaluation\n",
        "\n",
        "For image detection a classical metric is the ***Dice coefficient*** also referred to as ***F1 score*** and defined as\n",
        "\n",
        "$$ Dice(A, B) =  \\dfrac{2 \\times |A \\cap B|}{|A| + |B|} $$\n",
        "\n",
        "This metric is very sensitive to small shifts or area difference between truth and prediction.\n",
        "\n",
        "A perfect match would result in a Dice=1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UC6qAbpdwj5x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YJlCbTBTfrX"
      },
      "source": [
        "## Workflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vq9neAATfrY"
      },
      "source": [
        "The model needs to take the image blend as input and produce an other image as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlfhbpaaTfrZ"
      },
      "source": [
        "## Model\n",
        "\n",
        "The model is the part where you intervention is needed. A very basic (working) model is implemented below. It has two convolution layers. While it is very fast to train, it does not yield good results.\n",
        "\n",
        "Try to navigate the web/github to find appropriate models for this image segmentation task. Or build upon this existing model by complexifying it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "\n",
        "#Inputs\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "def model(inputs):\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Convlution layer \n",
        "    x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    \n",
        "    # Convolution layer\n",
        "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "\n",
        "###################################\n",
        "# Call Model\n",
        "###################################\n",
        "\n",
        "Model=model(inputs)\n",
        "\n",
        "Model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "Model.summary()\n"
      ],
      "metadata": {
        "id": "pf-NamcVXMwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GajKD_8yTfrZ"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlewURxMTfra"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "# Fit the Model\n",
        "##########################\n",
        "\n",
        "# CHANGE HERE THE NUMBER OF EPOCHS OR THE BATCH SIZE\n",
        "history=Model.fit(X_train,Y_train, batch_size=16,epochs=10, verbose=1, shuffle=True, validation_split=.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zTU9p8-Tfra"
      },
      "source": [
        "### Plot the history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('BCE loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "\n"
      ],
      "metadata": {
        "id": "T6MKjuYAwhLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(history.history['val_accuracy'])\n"
      ],
      "metadata": {
        "id": "9gZ4qIcSy49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i59isQK2Tfra"
      },
      "source": [
        "## Predict on the test set and score the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = Model.predict(X_test)[:,:,:,0] "
      ],
      "metadata": {
        "id": "K1MstVbZxCLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Dice Coefficient\n",
        "##########################\n",
        "\n",
        "def dice_coeff(y_true, y_pred, smooth=1e-4):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    intersection = tf.keras.backend.sum(y_true * y_pred, axis=(0, 1))\n",
        "    union = tf.keras.backend.sum(y_true, axis=(0, 1)) + tf.keras.backend.sum(y_pred, axis=(0, 1))\n",
        "    dice = (2. * intersection + smooth)/(union + smooth)\n",
        "    return dice\n",
        "\n",
        "print(f\"Score: {np.mean(dice_coeff(Y_test,Y_pred)):.2f}\")\n"
      ],
      "metadata": {
        "id": "MC0QDLH9VFs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbDsloy0Tfra"
      },
      "source": [
        "### Plot some examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "9bf0YWkCTfrb"
      },
      "outputs": [],
      "source": [
        "plot_random_results(X_test, Y_test, Y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.12.3"
    },
    "colab": {
      "name": "DeblendingGalaxiesTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}